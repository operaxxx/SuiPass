# SuiPass Walrus å­˜å‚¨é›†æˆæ¶æ„è®¾è®¡æ–‡æ¡£

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº† SuiPass é¡¹ç›®çš„ Walrus å­˜å‚¨é›†æˆæ¶æ„è®¾è®¡ã€‚åŸºäºç°æœ‰çš„æ™ºèƒ½åˆçº¦è®¾è®¡ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé«˜æ€§èƒ½ã€å®‰å…¨ä¸”æˆæœ¬ä¼˜åŒ–çš„å»ä¸­å¿ƒåŒ–å­˜å‚¨è§£å†³æ–¹æ¡ˆï¼Œå®Œç¾é€‚é… Sui åŒºå—é“¾å’Œ Walrus å­˜å‚¨ç³»ç»Ÿã€‚

### ğŸ¯ è®¾è®¡ç›®æ ‡

- **é«˜æ•ˆå­˜å‚¨**ï¼šé€šè¿‡å‹ç¼©å’Œåˆ†ç‰‡ä¼˜åŒ–å­˜å‚¨æˆæœ¬
- **å®‰å…¨å¯é **ï¼šç«¯åˆ°ç«¯åŠ å¯†ï¼Œç¡®ä¿æ•°æ®éšç§å’Œå®Œæ•´æ€§
- **æ€§èƒ½å“è¶Š**ï¼šç¼“å­˜æœºåˆ¶å’Œæ‰¹é‡æ“ä½œæå‡ç”¨æˆ·ä½“éªŒ
- **æˆæœ¬å¯æ§**ï¼šæ™ºèƒ½å‹ç¼©ç­–ç•¥é™ä½å­˜å‚¨è´¹ç”¨
- **æ˜“äºæ‰©å±•**ï¼šæ¨¡å—åŒ–è®¾è®¡æ”¯æŒæœªæ¥åŠŸèƒ½æ‰©å±•

## ğŸ—ï¸ æ•´ä½“æ¶æ„

### ç³»ç»Ÿæ¶æ„å›¾

```mermaid
graph TB
    A[å‰ç«¯åº”ç”¨] --> B[Walrus Storage Service]
    B --> C[åŠ å¯†å±‚]
    C --> D[Walrus Client]
    D --> E[Walrus Network]

    A --> F[æ™ºèƒ½åˆçº¦å±‚]
    F --> G[VaultRegistry]
    F --> H[AccessControl]

    B --> I[æœ¬åœ°ç¼“å­˜]
    I --> J[IndexedDB]

    C --> K[å¯†é’¥ç®¡ç†]
    K --> L[Argon2id]

    E --> M[Blob å­˜å‚¨]
    M --> N[ç‰ˆæœ¬æ§åˆ¶]
    N --> O[å¢é‡æ›´æ–°]
```

### æ•°æ®æµå›¾

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯åº”ç”¨
    participant E as åŠ å¯†æœåŠ¡
    participant W as Walrus å­˜å‚¨
    participant S as æ™ºèƒ½åˆçº¦
    participant C as ç¼“å­˜

    U->>F: åˆ›å»º/æ›´æ–°ä¿é™©åº“
    F->>E: åŠ å¯†æ•°æ®
    E-->>F: è¿”å›åŠ å¯†æ•°æ®
    F->>W: ä¸Šä¼ åˆ° Walrus
    W-->>F: è¿”å› blob_id
    F->>S: æ›´æ–° Vault å¼•ç”¨
    S-->>F: äº¤æ˜“ç¡®è®¤
    F->>C: æ›´æ–°ç¼“å­˜
    F-->>U: æ“ä½œå®Œæˆ

    U->>F: è®¿é—®ä¿é™©åº“
    F->>C: æ£€æŸ¥ç¼“å­˜
    alt ç¼“å­˜å‘½ä¸­
        C-->>F: è¿”å›ç¼“å­˜æ•°æ®
    else ç¼“å­˜æœªå‘½ä¸­
        F->>S: è·å– blob_id
        S-->>F: è¿”å› blob_id
        F->>W: ä¸‹è½½æ•°æ®
        W-->>F: è¿”å›åŠ å¯†æ•°æ®
        F->>E: è§£å¯†æ•°æ®
        E-->>F: è¿”å›æ˜æ–‡æ•°æ®
        F->>C: æ›´æ–°ç¼“å­˜
    end
    F-->>U: æ˜¾ç¤ºæ•°æ®
```

## ğŸ“Š Walrus æ•°æ®ç»“æ„è®¾è®¡

### 1. Blob æ•°æ®æ ¼å¼

#### 1.1 æ ¸å¿ƒæ•°æ®ç»“æ„

```typescript
// ä¸»ä¿é™©åº“æ•°æ®ç»“æ„
interface VaultBlob {
  metadata: VaultMetadata;
  folders: Folder[];
  passwords: PasswordItem[];
  settings: VaultSettings;
  version: number;
  checksum: string;
  compression: CompressionInfo;
}

// å…ƒæ•°æ®
interface VaultMetadata {
  id: string;
  name: string;
  description?: string;
  created_at: number;
  updated_at: number;
  total_items: number;
  total_size: number;
  encryption: EncryptionInfo;
}

// æ–‡ä»¶å¤¹ç»“æ„
interface Folder {
  id: string;
  name: string;
  parent_id?: string;
  icon?: string;
  color?: string;
  created_at: number;
  updated_at: number;
  item_count: number;
}

// å¯†ç æ¡ç›®
interface PasswordItem {
  id: string;
  title: string;
  username?: string;
  password: string;
  url?: string;
  notes?: string;
  folder_id?: string;
  tags: string[];
  custom_fields: CustomField[];
  created_at: number;
  updated_at: number;
  password_strength: number;
  last_used?: number;
}

// è‡ªå®šä¹‰å­—æ®µ
interface CustomField {
  name: string;
  value: string;
  type: "text" | "password" | "number" | "date" | "url";
  protected: boolean;
}

// åŠ å¯†ä¿¡æ¯
interface EncryptionInfo {
  algorithm: "AES-256-GCM";
  key_id: string;
  iv: string;
  version: number;
  key_derivation: {
    algorithm: "Argon2id";
    iterations: number;
    memory: number;
    parallelism: number;
    salt: string;
  };
}

// å‹ç¼©ä¿¡æ¯
interface CompressionInfo {
  algorithm: "gzip" | "brotli";
  ratio: number;
  original_size: number;
  compressed_size: number;
}
```

#### 1.2 ç‰ˆæœ¬æ§åˆ¶å’Œå¢é‡æ›´æ–°

```typescript
// å¢é‡æ›´æ–°ä¿¡æ¯
interface DeltaUpdate {
  version: number;
  base_version: number;
  changes: Change[];
  checksum: string;
}

// å˜æ›´è®°å½•
interface Change {
  type: "create" | "update" | "delete";
  entity: "password" | "folder";
  id: string;
  data?: any;
  timestamp: number;
}

// ç‰ˆæœ¬ç­–ç•¥
interface VersionStrategy {
  full_version_interval: number; // å…¨é‡ç‰ˆæœ¬é—´éš”
  max_delta_versions: number; // æœ€å¤§å¢é‡ç‰ˆæœ¬æ•°
  max_total_versions: number; // æœ€å¤§æ€»ç‰ˆæœ¬æ•°
  compression: {
    min_size_threshold: number; // æœ€å°å‹ç¼©é˜ˆå€¼
    compression_ratio_threshold: number; // å‹ç¼©æ¯”é˜ˆå€¼
  };
}
```

### 2. å­˜å‚¨åˆ†ç‰‡ç­–ç•¥

```typescript
interface BlobSharding {
  shardSize: number; // åˆ†ç‰‡å¤§å°
  maxParallelUploads: number; // æœ€å¤§å¹¶è¡Œä¸Šä¼ æ•°
  hashAlgorithm: "SHA-256" | "SHA-512"; // å“ˆå¸Œç®—æ³•
  redundancy: {
    parityShards: number; // æ ¡éªŒåˆ†ç‰‡æ•°
    dataShards: number; // æ•°æ®åˆ†ç‰‡æ•°
  };
}

interface BlobShard {
  id: string;
  index: number;
  data: Uint8Array;
  hash: string;
  size: number;
  checksum: string;
}
```

## ğŸ”§ å®¢æˆ·ç«¯é›†æˆè®¾è®¡

### 1. Walrus å­˜å‚¨æœåŠ¡

```typescript
// packages/frontend/src/services/walrus.ts
import { WalrusClient } from "@mysten/walrus";
import { EncryptionService } from "./encryption";
import { CacheService } from "./cache";
import { VaultBlob, DeltaUpdate } from "../types/walrus";

export class WalrusStorageService {
  private client: WalrusClient;
  private encryption: EncryptionService;
  private cache: CacheService;
  private retryAttempts = 3;
  private maxBlobSize = 10 * 1024 * 1024; // 10MB

  constructor() {
    this.client = new WalrusClient({
      network: process.env.VITE_WALRUS_NETWORK || "testnet",
      rpcUrl: process.env.VITE_WALRUS_RPC_URL,
    });
    this.encryption = new EncryptionService();
    this.cache = new CacheService();
  }

  /**
   * ä¸Šä¼ ä¿é™©åº“æ•°æ®
   */
  async uploadVault(vault: VaultBlob): Promise<string> {
    try {
      // 1. éªŒè¯æ•°æ®å®Œæ•´æ€§
      this.validateVault(vault);

      // 2. å‹ç¼©æ•°æ®
      const compressed = await this.compressVault(vault);

      // 3. åŠ å¯†æ•°æ®
      const encrypted = await this.encryption.encrypt(compressed);

      // 4. ä¸Šä¼ åˆ° Walrus
      const blobId = await this.uploadWithRetry(encrypted);

      // 5. æ›´æ–°ç¼“å­˜
      await this.cache.setVault(blobId, vault);

      return blobId;
    } catch (error) {
      console.error("Failed to upload vault:", error);
      throw new Error("Vault upload failed");
    }
  }

  /**
   * ä¸‹è½½ä¿é™©åº“æ•°æ®
   */
  async downloadVault(blobId: string): Promise<VaultBlob> {
    try {
      // 1. æ£€æŸ¥ç¼“å­˜
      const cached = await this.cache.getVault(blobId);
      if (cached) {
        return cached;
      }

      // 2. ä» Walrus ä¸‹è½½
      const encrypted = await this.downloadWithRetry(blobId);

      // 3. è§£å¯†æ•°æ®
      const decrypted = await this.encryption.decrypt(encrypted);

      // 4. è§£å‹æ•°æ®
      const vault = await this.decompressVault(decrypted);

      // 5. éªŒè¯æ•°æ®å®Œæ•´æ€§
      this.validateVault(vault);

      // 6. æ›´æ–°ç¼“å­˜
      await this.cache.setVault(blobId, vault);

      return vault;
    } catch (error) {
      console.error("Failed to download vault:", error);
      throw new Error("Vault download failed");
    }
  }

  /**
   * åˆ›å»ºå¢é‡æ›´æ–°
   */
  async createDeltaUpdate(
    currentVault: VaultBlob,
    previousVault: VaultBlob,
  ): Promise<DeltaUpdate> {
    const changes = this.calculateChanges(currentVault, previousVault);
    const delta: DeltaUpdate = {
      version: currentVault.version,
      base_version: previousVault.version,
      changes,
      checksum: await this.generateChecksum(changes),
    };

    return delta;
  }

  /**
   * åº”ç”¨å¢é‡æ›´æ–°
   */
  async applyDeltaUpdate(
    baseVault: VaultBlob,
    delta: DeltaUpdate,
  ): Promise<VaultBlob> {
    const updatedVault = this.applyChanges(baseVault, delta.changes);
    updatedVault.version = delta.version;
    updatedVault.updated_at = Date.now();

    return updatedVault;
  }

  /**
   * å¸¦é‡è¯•çš„ä¸Šä¼ 
   */
  private async uploadWithRetry(data: Uint8Array): Promise<string> {
    let lastError: Error;

    for (let attempt = 0; attempt < this.retryAttempts; attempt++) {
      try {
        const blobId = await this.client.uploadBlob({
          data,
          epochs: 10, // 10ä¸ªepochçš„å­˜å‚¨æ—¶é—´
        });
        return blobId;
      } catch (error) {
        lastError = error as Error;
        console.warn(`Upload attempt ${attempt + 1} failed:`, error);

        if (attempt < this.retryAttempts - 1) {
          await this.delay(1000 * Math.pow(2, attempt)); // æŒ‡æ•°é€€é¿
        }
      }
    }

    throw lastError!;
  }

  /**
   * å¸¦é‡è¯•çš„ä¸‹è½½
   */
  private async downloadWithRetry(blobId: string): Promise<Uint8Array> {
    let lastError: Error;

    for (let attempt = 0; attempt < this.retryAttempts; attempt++) {
      try {
        const blob = await this.client.downloadBlob(blobId);
        return blob.data;
      } catch (error) {
        lastError = error as Error;
        console.warn(`Download attempt ${attempt + 1} failed:`, error);

        if (attempt < this.retryAttempts - 1) {
          await this.delay(1000 * Math.pow(2, attempt));
        }
      }
    }

    throw lastError!;
  }

  /**
   * æ•°æ®å‹ç¼©
   */
  private async compressVault(vault: VaultBlob): Promise<Uint8Array> {
    const jsonString = JSON.stringify(vault);
    const encoder = new TextEncoder();
    const data = encoder.encode(jsonString);

    // ä½¿ç”¨ Brotli å‹ç¼©
    const compressed = new CompressionStream("gzip");
    // å®é™…å‹ç¼©å®ç°
    return data; // ç®€åŒ–å®ç°
  }

  /**
   * æ•°æ®è§£å‹
   */
  private async decompressVault(data: Uint8Array): Promise<VaultBlob> {
    // ä½¿ç”¨ Gzip è§£å‹
    const decompressed = new DecompressionStream("gzip");
    // å®é™…è§£å‹å®ç°
    const decoder = new TextDecoder();
    const jsonString = decoder.decode(data);
    return JSON.parse(jsonString);
  }

  /**
   * éªŒè¯ä¿é™©åº“æ•°æ®
   */
  private validateVault(vault: VaultBlob): void {
    if (!vault.metadata || !vault.metadata.id) {
      throw new Error("Invalid vault metadata");
    }

    if (!vault.checksum) {
      throw new Error("Missing vault checksum");
    }

    // éªŒè¯ç‰ˆæœ¬å·
    if (vault.version <= 0) {
      throw new Error("Invalid vault version");
    }

    // éªŒè¯æ•°æ®å¤§å°
    const estimatedSize = JSON.stringify(vault).length;
    if (estimatedSize > this.maxBlobSize) {
      throw new Error("Vault size exceeds maximum limit");
    }
  }

  /**
   * è®¡ç®—å˜æ›´
   */
  private calculateChanges(current: VaultBlob, previous: VaultBlob): Change[] {
    const changes: Change[] = [];

    // è®¡ç®—å¯†ç å˜æ›´
    const passwordMap = new Map(previous.passwords.map((p) => [p.id, p]));
    for (const password of current.passwords) {
      const previousPassword = passwordMap.get(password.id);
      if (!previousPassword) {
        changes.push({
          type: "create",
          entity: "password",
          id: password.id,
          data: password,
          timestamp: Date.now(),
        });
      } else if (
        JSON.stringify(password) !== JSON.stringify(previousPassword)
      ) {
        changes.push({
          type: "update",
          entity: "password",
          id: password.id,
          data: password,
          timestamp: Date.now(),
        });
      }
    }

    // æ£€æµ‹åˆ é™¤çš„å¯†ç 
    const currentPasswordIds = new Set(current.passwords.map((p) => p.id));
    for (const password of previous.passwords) {
      if (!currentPasswordIds.has(password.id)) {
        changes.push({
          type: "delete",
          entity: "password",
          id: password.id,
          timestamp: Date.now(),
        });
      }
    }

    return changes;
  }

  /**
   * åº”ç”¨å˜æ›´
   */
  private applyChanges(baseVault: VaultBlob, changes: Change[]): VaultBlob {
    const updatedVault = JSON.parse(JSON.stringify(baseVault));

    for (const change of changes) {
      switch (change.type) {
        case "create":
        case "update":
          if (change.entity === "password") {
            const index = updatedVault.passwords.findIndex(
              (p) => p.id === change.id,
            );
            if (index >= 0) {
              updatedVault.passwords[index] = change.data;
            } else {
              updatedVault.passwords.push(change.data);
            }
          }
          break;
        case "delete":
          if (change.entity === "password") {
            updatedVault.passwords = updatedVault.passwords.filter(
              (p) => p.id !== change.id,
            );
          }
          break;
      }
    }

    return updatedVault;
  }

  /**
   * ç”Ÿæˆæ ¡éªŒå’Œ
   */
  private async generateChecksum(data: any): Promise<string> {
    const jsonString = JSON.stringify(data);
    const encoder = new TextEncoder();
    const dataBuffer = encoder.encode(jsonString);
    const hashBuffer = await crypto.subtle.digest("SHA-256", dataBuffer);
    const hashArray = Array.from(new Uint8Array(hashBuffer));
    return hashArray.map((b) => b.toString(16).padStart(2, "0")).join("");
  }

  private delay(ms: number): Promise<void> {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
}
```

### 2. åŠ å¯†æœåŠ¡

```typescript
// packages/frontend/src/services/encryption.ts
import * as argon2 from "argon2-browser";

export class EncryptionService {
  private algorithm = "AES-256-GCM";
  private keyDerivationAlgorithm = "Argon2id";
  private keyLength = 256; // bits
  private ivLength = 12; // bytes for GCM

  /**
   * åŠ å¯†æ•°æ®
   */
  async encrypt(
    data: Uint8Array,
    masterPassword: string,
  ): Promise<EncryptedData> {
    try {
      // 1. ç”ŸæˆåŠ å¯†å¯†é’¥
      const key = await this.deriveKey(masterPassword);

      // 2. ç”Ÿæˆ IV
      const iv = crypto.getRandomValues(new Uint8Array(this.ivLength));

      // 3. åŠ å¯†æ•°æ®
      const encryptedData = await crypto.subtle.encrypt(
        {
          name: "AES-GCM",
          iv,
        },
        key,
        data,
      );

      // 4. æå–è®¤è¯æ ‡ç­¾
      const encryptedArray = new Uint8Array(encryptedData);
      const tag = encryptedArray.slice(-16); // GCM tag is 16 bytes
      const ciphertext = encryptedArray.slice(0, -16);

      return {
        algorithm: this.algorithm,
        ciphertext: Array.from(ciphertext),
        iv: Array.from(iv),
        tag: Array.from(tag),
        keyId: await this.getKeyId(key),
      };
    } catch (error) {
      console.error("Encryption failed:", error);
      throw new Error("Failed to encrypt data");
    }
  }

  /**
   * è§£å¯†æ•°æ®
   */
  async decrypt(
    encryptedData: EncryptedData,
    masterPassword: string,
  ): Promise<Uint8Array> {
    try {
      // 1. æ´¾ç”Ÿå¯†é’¥
      const key = await this.deriveKey(masterPassword);

      // 2. å‡†å¤‡æ•°æ®
      const ciphertext = new Uint8Array(encryptedData.ciphertext);
      const iv = new Uint8Array(encryptedData.iv);
      const tag = new Uint8Array(encryptedData.tag);

      // 3. åˆå¹¶å¯†æ–‡å’Œæ ‡ç­¾
      const encryptedWithTag = new Uint8Array(ciphertext.length + tag.length);
      encryptedWithTag.set(ciphertext);
      encryptedWithTag.set(tag, ciphertext.length);

      // 4. è§£å¯†
      const decrypted = await crypto.subtle.decrypt(
        {
          name: "AES-GCM",
          iv,
        },
        key,
        encryptedWithTag,
      );

      return new Uint8Array(decrypted);
    } catch (error) {
      console.error("Decryption failed:", error);
      throw new Error("Failed to decrypt data");
    }
  }

  /**
   * æ´¾ç”Ÿå¯†é’¥
   */
  private async deriveKey(masterPassword: string): Promise<CryptoKey> {
    try {
      // ä½¿ç”¨ Argon2id è¿›è¡Œå¯†é’¥æ´¾ç”Ÿ
      const salt = crypto.getRandomValues(new Uint8Array(16));
      const derivedKey = await argon2.hash({
        pass: masterPassword,
        salt: Array.from(salt),
        type: argon2.ArgonType.Argon2id,
        mem: 65536, // 64MB
        time: 3, // 3 iterations
        hashLen: this.keyLength / 8,
      });

      // å¯¼å…¥ä¸º CryptoKey
      return crypto.subtle.importKey(
        "raw",
        new Uint8Array(derivedKey.hash),
        { name: "AES-GCM" },
        false,
        ["encrypt", "decrypt"],
      );
    } catch (error) {
      console.error("Key derivation failed:", error);
      throw new Error("Failed to derive encryption key");
    }
  }

  /**
   * è·å–å¯†é’¥ID
   */
  private async getKeyId(key: CryptoKey): Promise<string> {
    const rawKey = await crypto.subtle.exportKey("raw", key);
    const hashBuffer = await crypto.subtle.digest("SHA-256", rawKey);
    const hashArray = Array.from(new Uint8Array(hashBuffer));
    return hashArray.map((b) => b.toString(16).padStart(2, "0")).join("");
  }

  /**
   * éªŒè¯å¯†ç å¼ºåº¦
   */
  async verifyPasswordStrength(password: string): Promise<PasswordStrength> {
    const score = this.calculatePasswordScore(password);
    const feedback = this.getPasswordFeedback(password);

    return {
      score,
      strength: this.getStrengthLevel(score),
      feedback,
    };
  }

  private calculatePasswordScore(password: string): number {
    let score = 0;

    // é•¿åº¦å¾—åˆ†
    if (password.length >= 8) score += 25;
    if (password.length >= 12) score += 15;
    if (password.length >= 16) score += 10;

    // å¤æ‚åº¦å¾—åˆ†
    if (/[a-z]/.test(password)) score += 10;
    if (/[A-Z]/.test(password)) score += 10;
    if (/[0-9]/.test(password)) score += 10;
    if (/[^a-zA-Z0-9]/.test(password)) score += 15;

    // å”¯ä¸€å­—ç¬¦å¾—åˆ†
    const uniqueChars = new Set(password).size;
    score += Math.min(uniqueChars * 2, 20);

    return Math.min(score, 100);
  }

  private getStrengthLevel(
    score: number,
  ): "weak" | "medium" | "strong" | "very-strong" {
    if (score < 40) return "weak";
    if (score < 60) return "medium";
    if (score < 80) return "strong";
    return "very-strong";
  }

  private getPasswordFeedback(password: string): string[] {
    const feedback: string[] = [];

    if (password.length < 8) {
      feedback.push("Password should be at least 8 characters long");
    }

    if (!/[a-z]/.test(password)) {
      feedback.push("Add lowercase letters");
    }

    if (!/[A-Z]/.test(password)) {
      feedback.push("Add uppercase letters");
    }

    if (!/[0-9]/.test(password)) {
      feedback.push("Add numbers");
    }

    if (!/[^a-zA-Z0-9]/.test(password)) {
      feedback.push("Add special characters");
    }

    if (new Set(password).size < password.length * 0.7) {
      feedback.push("Use more unique characters");
    }

    return feedback;
  }
}

interface EncryptedData {
  algorithm: string;
  ciphertext: number[];
  iv: number[];
  tag: number[];
  keyId: string;
}

interface PasswordStrength {
  score: number;
  strength: "weak" | "medium" | "strong" | "very-strong";
  feedback: string[];
}
```

### 3. ç¼“å­˜æœåŠ¡

```typescript
// packages/frontend/src/services/cache.ts
import { openDB, DBSchema, IDBPDatabase } from "idb";

interface CacheDB extends DBSchema {
  vaults: {
    key: string;
    value: {
      blobId: string;
      data: any;
      timestamp: number;
      size: number;
    };
    indexes: {
      "by-timestamp": number;
      "by-size": number;
    };
  };
  metadata: {
    key: string;
    value: {
      lastSync: number;
      totalSize: number;
      vaultCount: number;
    };
  };
}

export class CacheService {
  private db: Promise<IDBPDatabase<CacheDB>>;
  private maxCacheSize = 100 * 1024 * 1024; // 100MB
  private maxAge = 24 * 60 * 60 * 1000; // 24 hours

  constructor() {
    this.db = this.initDB();
  }

  private async initDB(): Promise<IDBPDatabase<CacheDB>> {
    return openDB<CacheDB>("suipass-cache", 1, {
      upgrade(db) {
        const vaultStore = db.createObjectStore("vaults", {
          keyPath: "blobId",
        });
        vaultStore.createIndex("by-timestamp", "timestamp");
        vaultStore.createIndex("by-size", "size");

        db.createObjectStore("metadata", { keyPath: "key" });
      },
    });
  }

  async setVault(blobId: string, data: any): Promise<void> {
    const db = await this.db;
    const size = JSON.stringify(data).length;
    const timestamp = Date.now();

    // æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
    await this.enforceCacheLimit();

    await db.put("vaults", {
      blobId,
      data,
      timestamp,
      size,
    });

    // æ›´æ–°å…ƒæ•°æ®
    await this.updateMetadata(size, 1);
  }

  async getVault(blobId: string): Promise<any | null> {
    const db = await this.db;
    const cached = await db.get("vaults", blobId);

    if (!cached) {
      return null;
    }

    // æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
    if (Date.now() - cached.timestamp > this.maxAge) {
      await db.delete("vaults", blobId);
      return null;
    }

    return cached.data;
  }

  async clearCache(): Promise<void> {
    const db = await this.db;
    await db.clear("vaults");
    await db.clear("metadata");
  }

  async getCacheStats(): Promise<CacheStats> {
    const db = await this.db;
    const vaults = await db.getAll("vaults");
    const metadata = await db.get("metadata", "stats");

    return {
      totalSize: vaults.reduce((sum, v) => sum + v.size, 0),
      vaultCount: vaults.length,
      lastSync: metadata?.lastSync || 0,
      oldestEntry:
        vaults.length > 0 ? Math.min(...vaults.map((v) => v.timestamp)) : 0,
    };
  }

  private async enforceCacheLimit(): Promise<void> {
    const db = await this.db;
    const stats = await this.getCacheStats();

    if (stats.totalSize <= this.maxCacheSize) {
      return;
    }

    // åˆ é™¤æœ€æ—§çš„æ¡ç›®ç›´åˆ°æ»¡è¶³å¤§å°é™åˆ¶
    const vaults = await db.getAllFromIndex("vaults", "by-timestamp");
    let currentSize = stats.totalSize;

    for (const vault of vaults) {
      if (currentSize <= this.maxCacheSize * 0.8) {
        // æ¸…ç†åˆ°80%é™åˆ¶
        break;
      }

      await db.delete("vaults", vault.blobId);
      currentSize -= vault.size;
    }

    // æ›´æ–°å…ƒæ•°æ®
    await this.updateMetadata(
      -stats.totalSize + currentSize,
      -stats.vaultCount + vaults.length,
    );
  }

  private async updateMetadata(
    sizeDelta: number,
    countDelta: number,
  ): Promise<void> {
    const db = await this.db;
    const metadata = await db.get("metadata", "stats");

    const newMetadata = {
      key: "stats",
      lastSync: Date.now(),
      totalSize: (metadata?.totalSize || 0) + sizeDelta,
      vaultCount: (metadata?.vaultCount || 0) + countDelta,
    };

    await db.put("metadata", newMetadata);
  }
}

interface CacheStats {
  totalSize: number;
  vaultCount: number;
  lastSync: number;
  oldestEntry: number;
}
```

## ğŸ”— æ™ºèƒ½åˆçº¦é›†æˆæ‰©å±•

### å­˜å‚¨ç®¡ç†åˆçº¦

```move
// packages/contracts/sources/suipass/storage_manager.move
#[allow(duplicate_alias)]
module suipass::storage_manager {
    use sui::object::{Self, UID, ID};
    use sui::tx_context::{Self, TxContext};
    use sui::clock::{Self, Clock};
    use sui::event;
    use sui::balance::{Self, Balance};
    use sui::sui::SUI;
    use std::string::String;
    use std::vector;

    /// å­˜å‚¨ä¿¡æ¯
    public struct StorageInfo has store, drop {
        blob_id: String,
        blob_size: u64,
        storage_epochs: u64,
        cost: u64,
        compression_ratio: u64,
        checksum: String,
    }

    /// å­˜å‚¨å¼•ç”¨å¯¹è±¡
    public struct StorageReference has key {
        id: UID,
        vault_id: ID,
        storage_info: StorageInfo,
        previous_storage: vector<StorageInfo>, // å†å²å­˜å‚¨ä¿¡æ¯
        total_cost: u64,
        created_at: u64,
        updated_at: u64,
    }

    /// å­˜å‚¨äº‹ä»¶
    public struct StorageUpdated has copy, drop {
        vault_id: ID,
        blob_id: String,
        blob_size: u64,
        cost: u64,
        timestamp: u64,
    }

    /// å­˜å‚¨æˆæœ¬è®¡ç®—å¸¸é‡
    const COST_PER_BYTE_EPOCH: u64 = 1; // æ¯å­—èŠ‚æ¯epochçš„æˆæœ¬
    const MIN_STORAGE_EPOCHS: u64 = 1;
    const MAX_STORAGE_EPOCHS: u64 = 100;

    /// åˆ›å»ºå­˜å‚¨å¼•ç”¨
    public fun create_storage_reference(
        vault_id: ID,
        blob_id: String,
        blob_size: u64,
        storage_epochs: u64,
        compression_ratio: u64,
        checksum: String,
        clock: &Clock,
        ctx: &mut TxContext
    ): StorageReference {
        let cost = calculate_storage_cost(blob_size, storage_epochs);
        let storage_info = StorageInfo {
            blob_id,
            blob_size,
            storage_epochs,
            cost,
            compression_ratio,
            checksum,
        };

        let timestamp = clock::timestamp_ms(clock) / 1000;
        let reference = StorageReference {
            id: object::new(ctx),
            vault_id,
            storage_info,
            previous_storage: vector::empty(),
            total_cost: cost,
            created_at: timestamp,
            updated_at: timestamp,
        };

        event::emit(StorageUpdated {
            vault_id,
            blob_id,
            blob_size,
            cost,
            timestamp,
        });

        reference
    }

    /// æ›´æ–°å­˜å‚¨å¼•ç”¨
    public fun update_storage_reference(
        reference: &mut StorageReference,
        new_blob_id: String,
        new_blob_size: u64,
        new_storage_epochs: u64,
        new_compression_ratio: u64,
        new_checksum: String,
        clock: &Clock,
        ctx: &mut TxContext
    ) {
        assert!(reference.vault_id == tx_context::sender(ctx), 0);

        // ä¿å­˜æ—§çš„ä¿¡æ¯
        let old_info = reference.storage_info;
        vector::push_back(&mut reference.previous_storage, old_info);

        // é™åˆ¶å†å²è®°å½•æ•°é‡
        if (vector::length(&reference.previous_storage) > 10) {
            vector::remove(&mut reference.previous_storage, 0);
        };

        // æ›´æ–°æ–°ä¿¡æ¯
        let new_cost = calculate_storage_cost(new_blob_size, new_storage_epochs);
        reference.storage_info = StorageInfo {
            blob_id: new_blob_id,
            blob_size: new_blob_size,
            storage_epochs: new_storage_epochs,
            cost: new_cost,
            compression_ratio: new_compression_ratio,
            checksum: new_checksum,
        };

        reference.total_cost = reference.total_cost + new_cost;
        reference.updated_at = clock::timestamp_ms(clock) / 1000;

        event::emit(StorageUpdated {
            vault_id: reference.vault_id,
            blob_id: new_blob_id,
            blob_size: new_blob_size,
            cost: new_cost,
            timestamp: reference.updated_at,
        });
    }

    /// è®¡ç®—å­˜å‚¨æˆæœ¬
    public fun calculate_storage_cost(blob_size: u64, epochs: u64): u64 {
        assert!(epochs >= MIN_STORAGE_EPOCHS && epochs <= MAX_STORAGE_EPOCHS, 1);
        blob_size * epochs * COST_PER_BYTE_EPOCH
    }

    /// è·å–å­˜å‚¨æ•ˆç‡
    public fun storage_efficiency(reference: &StorageReference): u64 {
        if (reference.total_cost == 0) {
            0
        } else {
            reference.storage_info.blob_size / reference.total_cost
        }
    }

    /// è·å–å­˜å‚¨ä¿¡æ¯
    public fun storage_info(reference: &StorageReference): (String, u64, u64, u64) {
        (
            reference.storage_info.blob_id,
            reference.storage_info.blob_size,
            reference.storage_info.compression_ratio,
            reference.storage_info.cost
        )
    }

    /// è·å–æ€»æˆæœ¬
    public fun total_cost(reference: &StorageReference): u64 {
        reference.total_cost
    }

    /// è·å–å†å²å­˜å‚¨ä¿¡æ¯æ•°é‡
    public fun history_count(reference: &StorageReference): u64 {
        vector::length(&reference.previous_storage)
    }

    /// éªŒè¯æ ¡éªŒå’Œ
    public fun verify_checksum(reference: &StorageReference, checksum: String): bool {
        reference.storage_info.checksum == checksum
    }

    /// è®¡ç®—å¹³å‡å‹ç¼©æ¯”
    public fun average_compression_ratio(reference: &StorageReference): u64 {
        let total_ratio = reference.storage_info.compression_ratio;
        let count = 1;

        let i = 0;
        let len = vector::length(&reference.previous_storage);
        while (i < len) {
            let info = vector::borrow(&reference.previous_storage, i);
            total_ratio = total_ratio + info.compression_ratio;
            count = count + 1;
            i = i + 1;
        };

        total_ratio / count
    }

    /// è·å–å­˜å‚¨ç»Ÿè®¡
    public fun storage_stats(reference: &StorageReference): (u64, u64, u64, u64) {
        (
            reference.total_cost,
            reference.storage_info.blob_size,
            reference.storage_info.storage_epochs,
            reference.storage_info.compression_ratio
        )
    }
}
```

## ğŸš€ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. Blob åˆ†ç‰‡æœåŠ¡

```typescript
class BlobShardingService {
  private strategy: BlobSharding = {
    shardSize: 2 * 1024 * 1024, // 2MB
    maxParallelUploads: 4,
    hashAlgorithm: "SHA-256",
    redundancy: {
      parityShards: 2,
      dataShards: 4,
    },
  };

  async splitBlob(data: Uint8Array): Promise<BlobShard[]> {
    const shards: BlobShard[] = [];
    const totalShards = Math.ceil(data.length / this.strategy.shardSize);

    for (let i = 0; i < totalShards; i++) {
      const start = i * this.strategy.shardSize;
      const end = Math.min(start + this.strategy.shardSize, data.length);
      const shardData = data.slice(start, end);

      const hash = await this.calculateHash(shardData);

      shards.push({
        id: `${i}`,
        index: i,
        data: shardData,
        hash,
        size: shardData.length,
        checksum: await this.generateChecksum(shardData),
      });
    }

    return shards;
  }

  async mergeBlob(shards: BlobShard[]): Promise<Uint8Array> {
    // æŒ‰ç´¢å¼•æ’åº
    const sortedShards = shards.sort((a, b) => a.index - b.index);

    // è®¡ç®—æ€»å¤§å°
    const totalSize = sortedShards.reduce((sum, shard) => sum + shard.size, 0);
    const result = new Uint8Array(totalSize);

    // åˆå¹¶æ•°æ®
    let offset = 0;
    for (const shard of sortedShards) {
      result.set(shard.data, offset);
      offset += shard.size;
    }

    return result;
  }

  private async calculateHash(data: Uint8Array): Promise<string> {
    const hashBuffer = await crypto.subtle.digest(
      this.strategy.hashAlgorithm,
      data,
    );
    const hashArray = Array.from(new Uint8Array(hashBuffer));
    return hashArray.map((b) => b.toString(16).padStart(2, "0")).join("");
  }

  private async generateChecksum(data: Uint8Array): Promise<string> {
    return this.calculateHash(data);
  }
}
```

### 2. æ‰¹é‡æ“ä½œä¼˜åŒ–

```typescript
class BatchOperationService {
  private maxBatchSize = 10;
  private maxConcurrentBatches = 3;

  async batchUpload(vaults: VaultBlob[]): Promise<string[]> {
    const results: string[] = [];
    const batches = this.createBatches(vaults);

    // å¹¶è¡Œå¤„ç†æ‰¹æ¬¡
    const batchPromises = batches
      .slice(0, this.maxConcurrentBatches)
      .map((batch) => this.processBatch(batch));

    const batchResults = await Promise.all(batchPromises);
    batchResults.forEach((result) => results.push(...result));

    return results;
  }

  private createBatches(vaults: VaultBlob[]): VaultBlob[][] {
    const batches: VaultBlob[][] = [];

    for (let i = 0; i < vaults.length; i += this.maxBatchSize) {
      batches.push(vaults.slice(i, i + this.maxBatchSize));
    }

    return batches;
  }

  private async processBatch(batch: VaultBlob[]): Promise<string[]> {
    const results: string[] = [];

    for (const vault of batch) {
      try {
        const blobId = await this.uploadSingleVault(vault);
        results.push(blobId);
      } catch (error) {
        console.error("Failed to upload vault:", error);
        // ç»§ç»­å¤„ç†å…¶ä»–vault
      }
    }

    return results;
  }

  private async uploadSingleVault(vault: VaultBlob): Promise<string> {
    // å®ç°å•ä¸ªvaultä¸Šä¼ é€»è¾‘
    return "blob_id";
  }
}
```

## ğŸ”’ å®‰å…¨è€ƒè™‘

### å¯†é’¥ç®¡ç†

```typescript
class KeyManager {
  private masterKey: CryptoKey | null = null;
  private keyCache = new Map<string, CryptoKey>();
  private keyDerivationCache = new Map<string, string>();

  async initialize(masterPassword: string): Promise<void> {
    this.masterKey = await this.deriveMasterKey(masterPassword);
  }

  async deriveVaultKey(vaultId: string): Promise<CryptoKey> {
    if (this.keyCache.has(vaultId)) {
      return this.keyCache.get(vaultId)!;
    }

    if (!this.masterKey) {
      throw new Error("Key manager not initialized");
    }

    const salt = new TextEncoder().encode(vaultId);
    const keyMaterial = await crypto.subtle.deriveKey(
      {
        name: "HKDF",
        salt,
        info: new TextEncoder().encode("vault-encryption"),
        hash: "SHA-256",
      },
      this.masterKey,
      { name: "AES-GCM", length: 256 },
      false,
      ["encrypt", "decrypt"],
    );

    this.keyCache.set(vaultId, keyMaterial);
    return keyMaterial;
  }

  async clearSensitiveData(): Promise<void> {
    this.masterKey = null;
    this.keyCache.clear();
    this.keyDerivationCache.clear();
  }

  private async deriveMasterKey(masterPassword: string): Promise<CryptoKey> {
    const encoder = new TextEncoder();
    const data = encoder.encode(masterPassword);

    const key = await crypto.subtle.importKey(
      "raw",
      data,
      { name: "PBKDF2" },
      false,
      ["deriveBits", "deriveKey"],
    );

    return crypto.subtle.deriveKey(
      {
        name: "PBKDF2",
        salt: crypto.getRandomValues(new Uint8Array(32)),
        iterations: 100000,
        hash: "SHA-256",
      },
      key,
      { name: "AES-GCM", length: 256 },
      false,
      ["encrypt", "decrypt"],
    );
  }
}
```

## ğŸ’° æˆæœ¬ä¼°ç®—æ¨¡å‹

### æˆæœ¬è®¡ç®—å™¨

```typescript
class CostEstimator {
  private costPerByteEpoch = 0.000001; // 0.000001 SUI per byte per epoch
  private compressionRatio = 0.3; // 70% compression
  private epochsPerMonth = 720; // å‡è®¾æ¯å°æ—¶ä¸€ä¸ªepoch

  estimateMonthlyCost(vaultSize: number): number {
    const compressedSize = vaultSize * this.compressionRatio;
    const monthlyCost =
      compressedSize * this.costPerByteEpoch * this.epochsPerMonth;
    return monthlyCost;
  }

  estimateUploadCost(vaultSize: number): number {
    const compressedSize = vaultSize * this.compressionRatio;
    return compressedSize * this.costPerByteEpoch * 10; // 10 epochs minimum
  }

  getCostBreakdown(vaultSize: number): CostBreakdown {
    const compressedSize = vaultSize * this.compressionRatio;
    const uploadCost = this.estimateUploadCost(vaultSize);
    const monthlyCost = this.estimateMonthlyCost(vaultSize);

    return {
      originalSize: vaultSize,
      compressedSize,
      compressionRatio: this.compressionRatio,
      uploadCost,
      monthlyCost,
      yearlyCost: monthlyCost * 12,
      costSavings:
        vaultSize * this.costPerByteEpoch * this.epochsPerMonth * 12 -
        monthlyCost * 12,
    };
  }
}

interface CostBreakdown {
  originalSize: number;
  compressedSize: number;
  compressionRatio: number;
  uploadCost: number;
  monthlyCost: number;
  yearlyCost: number;
  costSavings: number;
}
```

## ğŸ“Š ç›‘æ§å’Œåˆ†æ

### å­˜å‚¨ç›‘æ§æœåŠ¡

```typescript
class StorageMonitor {
  private metrics = new Map<string, StorageMetrics>();

  recordUpload(blobId: string, size: number, duration: number): void {
    const metrics = this.metrics.get(blobId) || {
      blobId,
      uploadCount: 0,
      downloadCount: 0,
      totalSize: 0,
      averageUploadTime: 0,
      averageDownloadTime: 0,
      errorCount: 0,
      lastActivity: Date.now(),
    };

    metrics.uploadCount++;
    metrics.totalSize += size;
    metrics.averageUploadTime =
      (metrics.averageUploadTime * (metrics.uploadCount - 1) + duration) /
      metrics.uploadCount;
    metrics.lastActivity = Date.now();

    this.metrics.set(blobId, metrics);
  }

  recordDownload(blobId: string, duration: number): void {
    const metrics =
      this.metrics.get(blobId) || this.createDefaultMetrics(blobId);

    metrics.downloadCount++;
    metrics.averageDownloadTime =
      (metrics.averageDownloadTime * (metrics.downloadCount - 1) + duration) /
      metrics.downloadCount;
    metrics.lastActivity = Date.now();

    this.metrics.set(blobId, metrics);
  }

  recordError(blobId: string, error: string): void {
    const metrics =
      this.metrics.get(blobId) || this.createDefaultMetrics(blobId);

    metrics.errorCount++;
    metrics.lastActivity = Date.now();

    this.metrics.set(blobId, metrics);
  }

  getMetrics(blobId?: string): StorageMetrics | StorageMetrics[] {
    if (blobId) {
      return this.metrics.get(blobId) || this.createDefaultMetrics(blobId);
    }
    return Array.from(this.metrics.values());
  }

  getHealthStatus(): HealthStatus {
    const allMetrics = Array.from(this.metrics.values());
    const totalUploads = allMetrics.reduce((sum, m) => sum + m.uploadCount, 0);
    const totalDownloads = allMetrics.reduce(
      (sum, m) => sum + m.downloadCount,
      0,
    );
    const totalErrors = allMetrics.reduce((sum, m) => sum + m.errorCount, 0);
    const averageUploadTime =
      allMetrics.reduce((sum, m) => sum + m.averageUploadTime, 0) /
      allMetrics.length;
    const averageDownloadTime =
      allMetrics.reduce((sum, m) => sum + m.averageDownloadTime, 0) /
      allMetrics.length;

    return {
      totalBlobs: allMetrics.length,
      totalUploads,
      totalDownloads,
      totalErrors,
      errorRate: totalErrors / (totalUploads + totalDownloads) || 0,
      averageUploadTime,
      averageDownloadTime,
      lastActivity: Math.max(...allMetrics.map((m) => m.lastActivity)),
    };
  }

  private createDefaultMetrics(blobId: string): StorageMetrics {
    return {
      blobId,
      uploadCount: 0,
      downloadCount: 0,
      totalSize: 0,
      averageUploadTime: 0,
      averageDownloadTime: 0,
      errorCount: 0,
      lastActivity: Date.now(),
    };
  }
}

interface StorageMetrics {
  blobId: string;
  uploadCount: number;
  downloadCount: number;
  totalSize: number;
  averageUploadTime: number;
  averageDownloadTime: number;
  errorCount: number;
  lastActivity: number;
}

interface HealthStatus {
  totalBlobs: number;
  totalUploads: number;
  totalDownloads: number;
  totalErrors: number;
  errorRate: number;
  averageUploadTime: number;
  averageDownloadTime: number;
  lastActivity: number;
}
```

## ğŸ¯ é»‘å®¢æ¾æ¼”ç¤ºç­–ç•¥

### æ¼”ç¤ºåœºæ™¯è®¾è®¡

#### 1. **æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤º**

- åˆ›å»ºä¸ªäººä¿é™©åº“
- ä¸Šä¼ åŠ å¯†å¯†ç æ•°æ®
- å®æ—¶æƒé™åˆ†äº«
- ç‰ˆæœ¬å›æ»šåŠŸèƒ½

#### 2. **æŠ€æœ¯äº®ç‚¹å±•ç¤º**

- Gas ä¼˜åŒ–æ•ˆæœå¯¹æ¯”
- å®‰å…¨è¯„åˆ†ç³»ç»Ÿ
- å®¡è®¡æ—¥å¿—è¿½è¸ª
- Walrus å­˜å‚¨é›†æˆ

#### 3. **ç”¨æˆ·ä½“éªŒæ¼”ç¤º**

- ç®€æ´çš„ç•Œé¢æ“ä½œ
- å®æ—¶çŠ¶æ€æ›´æ–°
- æƒé™ç®¡ç†æµç¨‹
- æ•°æ®æ¢å¤åŠŸèƒ½

### æ¼”ç¤ºæµç¨‹å›¾

```mermaid
graph TD
    A[å¼€å§‹æ¼”ç¤º] --> B[åˆ›å»ºä¿é™©åº“]
    B --> C[ä¸Šä¼ å¯†ç æ•°æ®]
    C --> D[è®¾ç½®è®¿é—®æƒé™]
    D --> E[åˆ†äº«ç»™å›¢é˜Ÿæˆå‘˜]
    E --> F[å±•ç¤ºå®æ—¶åŒæ­¥]
    F --> G[æ¼”ç¤ºç‰ˆæœ¬å›æ»š]
    G --> H[æ˜¾ç¤ºå®‰å…¨è¯„åˆ†]
    H --> I[å±•ç¤ºå®¡è®¡æ—¥å¿—]
    I --> J[æ€»ç»“æŠ€æœ¯ä¼˜åŠ¿]
    J --> K[ç»“æŸæ¼”ç¤º]
```

### æ€§èƒ½æ•°æ®å±•ç¤º

```mermaid
pie
    title å­˜å‚¨æˆæœ¬åˆ†å¸ƒ
    "é“¾ä¸Šå…ƒæ•°æ®" : 5
    "Walrus å­˜å‚¨æ•°æ®" : 90
    "å®¡è®¡æ—¥å¿—" : 3
    "æƒé™ä¿¡æ¯" : 2
```

```mermaid
bar
    title æ€§èƒ½ä¼˜åŒ–å¯¹æ¯”
    x-axis ä¼˜åŒ–é¡¹ç›®
    y-axis æ€§èƒ½æå‡ç™¾åˆ†æ¯”
    series ä¼˜åŒ–æ•ˆæœ
    data [80, 75, 60, 70]
    categories ["å‹ç¼©ä¼˜åŒ–", "å¢é‡æ›´æ–°", "æ‰¹é‡æ“ä½œ", "ç¼“å­˜æœºåˆ¶"]
```

## ğŸ“‹ å¼€å‘æ—¶é—´è§„åˆ’

### é»‘å®¢æ¾å¼€å‘è®¡åˆ’

| é˜¶æ®µ  | æ—¶é—´  | ä»»åŠ¡         | äº¤ä»˜ç‰©               |
| ----- | ----- | ------------ | -------------------- |
| Day 1 | 6å°æ—¶ | æ ¸å¿ƒå­˜å‚¨æœåŠ¡ | Walrusä¸Šä¼ ä¸‹è½½åŠŸèƒ½   |
| Day 2 | 6å°æ—¶ | åŠ å¯†å’Œç¼“å­˜   | æ•°æ®åŠ å¯†ã€ç¼“å­˜æœºåˆ¶   |
| Day 3 | 6å°æ—¶ | æ™ºèƒ½åˆçº¦é›†æˆ | å­˜å‚¨ç®¡ç†åˆçº¦         |
| Day 4 | 6å°æ—¶ | æ€§èƒ½ä¼˜åŒ–     | åˆ†ç‰‡ã€å‹ç¼©ã€æ‰¹é‡æ“ä½œ |
| Day 5 | 6å°æ—¶ | æ¼”ç¤ºå’Œæµ‹è¯•   | å®Œæ•´æ¼”ç¤ºç³»ç»Ÿ         |

### é£é™©è¯„ä¼°

| é£é™©           | æ¦‚ç‡ | å½±å“ | ç¼“è§£æªæ–½         |
| -------------- | ---- | ---- | ---------------- |
| Walrusé›†æˆé—®é¢˜ | ä¸­   | é«˜   | å‡†å¤‡å¤‡ç”¨å­˜å‚¨æ–¹æ¡ˆ |
| Gasæˆæœ¬è¿‡é«˜    | ä½   | ä¸­   | ä¼˜åŒ–æ•°æ®ç»“æ„     |
| å‰ç«¯é›†æˆå»¶è¿Ÿ   | ä¸­   | ä¸­   | ä½¿ç”¨ç®€åŒ–UI       |
| æƒé™ç³»ç»Ÿå¤æ‚   | ä½   | ä½   | ç®€åŒ–æƒé™æ¨¡å‹     |

## ğŸ”§ æ‰©å±•å»ºè®®

### çŸ­æœŸæ‰©å±• (1-2å‘¨)

- **å¤šå› ç´ è®¤è¯**ï¼šé›†æˆ 2FA æ”¯æŒ
- **æ•°æ®å¯¼å…¥å¯¼å‡º**ï¼šæ”¯æŒä¸»æµå¯†ç ç®¡ç†å™¨æ ¼å¼
- **æµè§ˆå™¨æ‰©å±•**ï¼šæä¾›è‡ªåŠ¨å¡«å……åŠŸèƒ½

### ä¸­æœŸæ‰©å±• (1-2æœˆ)

- **å›¢é˜Ÿåä½œ**ï¼šæ”¯æŒå¤šç”¨æˆ·åä½œ
- **é«˜çº§åˆ†äº«**ï¼šæ›´çµæ´»çš„åˆ†äº«ç­–ç•¥
- **API é›†æˆ**ï¼šæä¾›ç¬¬ä¸‰æ–¹é›†æˆæ¥å£

### é•¿æœŸæ‰©å±• (3-6æœˆ)

- **ä¼ä¸šåŠŸèƒ½**ï¼šä¼ä¸šçº§å®‰å…¨å’Œç®¡ç†åŠŸèƒ½
- **ç§»åŠ¨ç«¯**ï¼šç§»åŠ¨åº”ç”¨æ”¯æŒ
- **é«˜çº§åˆ†æ**ï¼šå®‰å…¨åˆ†æå’ŒæŠ¥å‘ŠåŠŸèƒ½

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

1. **æŠ€æœ¯å…ˆè¿›æ€§**
   - åŸºäº Sui + Walrus çš„å»ä¸­å¿ƒåŒ–æ¶æ„
   - ç«¯åˆ°ç«¯åŠ å¯†ç¡®ä¿æ•°æ®å®‰å…¨
   - æ¨¡å—åŒ–è®¾è®¡ä¾¿äºç»´æŠ¤å’Œæ‰©å±•

2. **æ€§èƒ½ä¼˜åŠ¿**
   - å‹ç¼©ç®—æ³•èŠ‚çœ 70% å­˜å‚¨ç©ºé—´
   - å¢é‡æ›´æ–°å‡å°‘ 80% å¸¦å®½ä½¿ç”¨
   - å¤šå±‚ç¼“å­˜æå‡è®¿é—®é€Ÿåº¦

3. **æˆæœ¬ä¼˜åŠ¿**
   - æ™ºèƒ½å‹ç¼©ç­–ç•¥é™ä½å­˜å‚¨æˆæœ¬
   - æ‰¹é‡æ“ä½œä¼˜åŒ–äº¤æ˜“è´¹ç”¨
   - ç²¾ç¡®çš„æˆæœ¬ä¼°ç®—å’Œæ§åˆ¶

4. **å®‰å…¨ä¼˜åŠ¿**
   - AES-256-GCM + Argon2id åŠ å¯†
   - å®Œæ•´çš„å®¡è®¡æ—¥å¿—ç³»ç»Ÿ
   - æ•°æ®å®Œæ•´æ€§éªŒè¯æœºåˆ¶

### åˆ›æ–°äº®ç‚¹

- **åˆ†å±‚å­˜å‚¨æ¶æ„**ï¼šé“¾ä¸Šå…ƒæ•°æ® + Walrus æ•°æ®å­˜å‚¨
- **æ™ºèƒ½å‹ç¼©ç­–ç•¥**ï¼šåŠ¨æ€é€‰æ‹©æœ€ä½³å‹ç¼©ç®—æ³•
- **å¢é‡æ›´æ–°æœºåˆ¶**ï¼šåªä¼ è¾“å˜æ›´æ•°æ®
- **å®Œæ•´ç›‘æ§ç³»ç»Ÿ**ï¼šå®æ—¶æ€§èƒ½å’Œæˆæœ¬ç›‘æ§

è¿™ä¸ª Walrus å­˜å‚¨é›†æˆæ¶æ„è®¾è®¡ä¸º SuiPass é¡¹ç›®æä¾›äº†å®Œæ•´çš„å»ä¸­å¿ƒåŒ–å­˜å‚¨è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡ç»“åˆ Sui æ™ºèƒ½åˆçº¦å’Œ Walrus å­˜å‚¨ï¼Œæˆ‘ä»¬å®ç°äº†æ—¢å®‰å…¨åˆé«˜æ•ˆçš„å¯†ç ç®¡ç†ç³»ç»Ÿï¼Œä¸ºé»‘å®¢æ¾æ¼”ç¤ºæä¾›äº†åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025å¹´9æœˆ  
**æœ€åæ›´æ–°**: 2025å¹´9æœˆ  
**ç»´æŠ¤è€…**: SuiPasså¼€å‘å›¢é˜Ÿ
